---
title: 'Project 2: Modeling, Testing, and Predicting'
author: "SDS348"
date: ''
output:
  pdf_document:
    toc: yes
  html_document:
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: yes
---

```{r setup, include=FALSE}
library(knitr)
hook_output = knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
  # this hook is used only when the linewidth option is not NULL
  if (!is.null(n <- options$linewidth)) {
    x = knitr:::split_lines(x)
    # any lines wider than n should be wrapped
    if (any(nchar(x) > n)) x = strwrap(x, width = n)
    x = paste(x, collapse = '\n')
  }
  hook_output(x, options)
})

knitr::opts_chunk$set(echo = TRUE, eval = TRUE,fig.align="center",warning=FALSE,message=FALSE,fig.width=8, fig.height=5, linewidth=60)
options(tibble.width = 100,width = 100)
library(tidyverse)
```

# Modeling

## Australia Climate Data:
This project will focus on analyzing climate in Australia. Climate data for temperature and rainfall was gathered from the Australian Bureau of Meterology (BoM) at 5 major Australian cities: Sydney, Perth, Brisbane, Canberra, and Melbourne. Minimum and maximum temperature in celsius was sourced from BoM Climate Data Online. The temperature dataset includes the variables city_name, data, temperature, temp_type (min, max), and site_name (weather station). The rainfall dataset contains the weather station_code and station_name, city_name, year, month, day, rainfall in millimeters, period (how many days rainfall was collected across), quality (certified quality or not), latitude, and longitude. The temperature (temp) dataset has 528,278 entries dating back to 1910 and the rainfall (rain) dataset has 179,273 entries dating back to 1967. After joining the datasets using inner_join and removing missing values, 83,913 observations were left.

```{r}
# upload data
rain <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-01-07/rainfall.csv')
temp <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-01-07/temperature.csv')

# tidy the data
temp <- temp %>% separate(date, c("year","month", "day"), sep = "-") # separate data column

rain$city_name <- toupper(rain$city_name) # coerce city names to uppercase

temp[, 2:4] <- sapply(temp[, 2:4], as.character) # coerce into numeric
rain[, 3:5] <- sapply(rain[, 3:5], as.character) # coerce into numeric

# join datasets
climate <- inner_join(rain, temp, by = c("city_name", "year", "month", "day")) %>% na.omit() 
```


## MANOVA
```{r}
# assumptions
ggplot(climate, aes(x = temperature, y = period)) + geom_point(alpha = .5) + geom_density_2d(h=2) + coord_fixed() + facet_wrap(~city_name) # multivariate normality

# MANOVA
man1<-manova(cbind(climate$rainfall, climate$temperature, climate$period)~city_name, data=climate)
summary(man1)

# Univariate ANOVAs - all variables were significant
summary.aov(man1)

# post-hoc tests
pairwise.t.test(climate$rainfall, climate$city_name, p.adj="none") # rainfall

pairwise.t.test(climate$temperature, climate$city_name, p.adj="none") # temperature

pairwise.t.test(climate$period, climate$city_name, p.adj="none") # period

# adjusted p-value
alpha <- 0.05/7 ; alpha
```
*A one-way MANOVA was conducted to determine the effect of the city (Perth, Brisbane, Sydney, Canberra, Melbourne) on three dependent variables (temperature, rainfall, period). Examination of bivariate density plots for each group revealed stark deparures from multivariate normality. Most likely homogeneity of covariances assumption is also not met. Significant differences were found among the five cities for at least one of the dependent variables, Pillia trace = 0.17024, F(12,251724) = 1262, p-value < 2.2e-16.*

*Univariate ANOVAs for each dependent variable were conducted as follow-up tests to the MANOVA, using the Bonferroni method for controlling Type I error rates for multiple comparisons. The univariate ANOVAs for temperature, rainfall, and period were also significant, F(4,83908) = 3429.8, p < 2.2e-16 ; F(4,83908) = 232.71, p < 2.2e-16, and F(4,83908) = 469.15, p < 2.2e-16, respectively.*

*Post hoc analysis was performed conducting pairwise comparisons to determine which city differed in temperate, rainfall, and period. All cities differed for rainfall except Perth and Brisbane after adjusting for multiple comparisons (bonferroni). For temperature, all differed except for Melbourne and Canberra after adjusting for multiple comparisons (bonferroni). For period, Perth did not differ from Melbourne, and Sydney did not differ from Canberra after adjusting for multiple comparisons (bonferroni).*


## Randomization Test
```{r}
# check mean rainfall and temperature for each city
climate %>% group_by(city_name) %>% summarize(mean_rain=mean(rainfall), mean_temp=mean(temperature))

# randomization test comparing rainfall in Brisbane and Perth, Australia
rand_dist<-vector()
for(i in 1:5000){ 
  new <- data.frame(rainfall=sample(climate$rainfall),temperature=sample(climate$temperature),city=sample(climate$city_name)) 
  rand_dist[i]<-mean(new[new$city=="BRISBANE",]$rainfall)-mean(new[new$city=="PERTH",]$rainfall)
}

# actual
actual <- climate%>%filter(city_name==c("BRISBANE","PERTH"))%>%group_by(city_name)%>% summarize(means=mean(rainfall))%>%summarize(`mean_diff:`=diff(means))

# plot distribution of mean differences
hist(rand_dist,main="",ylab=""); abline(v = actual,col="red")

# p-value
mean(rand_dist > 0.116 | rand_dist < -0.116)
```
*The null hypothesis is that mean rainfall in millimeters is the same in Brisbane and in Perth. The alternative hypothesis is that mean rainfall in millimeters is different in Brisbane and in Perth. After performing a randomization test, we fail to reject the null hypothesis given that the p-value is 0.4662.*


## Linear Regression
```{r}
# center temperature
climate$temp_cent <- climate$temperature - mean(climate$temperature)

# linear regression
fit <- lm(rainfall~temp_cent*period*city_name, data=climate) ; summary(fit)

# plot fit
climate %>% ggplot(aes(x=period, y=rainfall)) + geom_point() + geom_smooth(method="lm")

# check assumptions
plot(fit$fitted.values, fit$residuals) # homoskedasticity and linearity not met
hist(fit$residuals) # normality not met
```
*The coefficient estimate of the intercept is the expected average rainfall in millimeters when we consider temperature in celsius, the number of days in which rainfall was collected across (period) and city. Thus, there are -0.75205 mm of rain on average, which in reality does not make sense. With all other variables accounted for, the significant coefficient estimates for city were -24.74053, 4.13981, 3.87261, for Canberra, Melbourne, and Perth, respectively. These mean that for every 1 mm increase in rainfall in that city, the overall average rainfall decrease by 24.74 mm when Canberra is looked at, and increases by 4.14 for Melbourne, for example. The interaction between city and period represents the additional effect these two variables have on average rainfall.*

```{r message=TRUE}
# recompute linear regression
library(lmtest)
library(sandwich)
coeftest(fit, vcov=vcovHC(fit))

# R-squared
(sum((climate$rainfall-mean(climate$rainfall))^2)-sum(fit$residuals^2))/sum((climate$rainfall-mean(climate$rainfall))^2)
```
*According to the residuals vs fitted values plot, the data does not meet the homoskedasticity and linearity assumptions and the histogram of residuals proves the data does not meet normality either. The regression was repeated with heteroskedasticity robust standard errors and only Melbourne, period, and their interaction were significantly affecting average rainfall. The p-value increased for both Melbourne and the interaction with period. The R-squared is 0.03061277m therefore our model explains 3.07% of the variation in rainfall*


## Bootstrapped Standard Errors on a Regression Model
```{r}
set.seed(348)
samp_distn <- replicate(5000, {
boot_dat <- sample_frac(climate, replace = T) # bootstrap data 
fit2 <- lm(rainfall~temp_cent*period*city_name, data = boot_dat) # fit model
coef(fit2) #save coefs
})

# estimated SEs
samp_distn %>% t %>% as.data.frame %>% summarize_all(sd)
```
*The standard errors of Canberra, Perth, temp_cent:Canberra, and period:Perth increased the most, and only the SE of Sydney decreased. No SEs were given for period:Canberra, period:Sydney even though the original linear model previously gave them.*


## Logistic Regression
```{r}
# create binary variable
climate$temp_type <- ifelse(climate$temp_type=='max', 1,0)

# logistic regression
fit3 <- glm(temp_type~rainfall*period*city_name*temperature, data=climate, family=binomial(link="logit")) ; summary(fit3)
```
*The coefficient estimate for the city of Melbourne is positive (7.117), meaning that all else equal, Melbourne temperature readings are more likely to predict minimum and maximum temperature than any other city. Temperature also had a positive coefficient estimate (6.299e-01), but the interaction between Melbourne and temperature did not(-1.527e-01)*

```{r}
# confusion matrix
prob <- predict(fit3, type = "response") 
table(xpredict = as.numeric(prob > 0.5), truth = climate$temp_type) %>% addmargins
(34240+34847)/83913 # accuracy
34847/41966 # sensitivity
34240/41947 # specificity
34847/42554 # precision
```
*The confusion matrix shows that our model has a precision of 81.89%. It correctly predicts maximum temperature type 83.04% of the time, and correctly predicts minimum temperature 81.63% of the time. Overall, the model has an accuracy of 82.33%.*

```{r}
# density plot of log-odds
climate$logit<-predict(fit3,type="link")

climate%>%ggplot(aes(logit,color=city_name,fill=city_name))+geom_density(alpha=.4)+ theme(legend.position=c(.85,.85))+geom_vline(xintercept=0)+xlab("predictor (logit)")
```

```{r}
# ROC curve
library(plotROC)
ROCprob <- ggplot(climate) + geom_roc(aes(d = temp_type, m = prob),
n.cuts = 0) ; ROCprob

# AUC calculation
calc_auc(ROCprob)
```
*The AUC has a value of 0.9187, indicating that the logistic regression is a great model for predicting minimum and maximum temperature in celsius.*

    
```{r}
## GIVE IT PREDICTED PROBS AND TRUTH LABELS, RETURNS VARIOUS DIAGNOSTICS
class_diag <- function(probs,truth){
#CONFUSION MATRIX: CALCULATE ACCURACY, TPR, TNR, PPV 
  tab<-table(factor(probs>.5,levels=c("FALSE","TRUE")),truth) 
  acc=sum(diag(tab))/sum(tab)
  sens=tab[2,2]/colSums(tab)[2]
  spec=tab[1,1]/colSums(tab)[1]
  ppv=tab[2,2]/rowSums(tab)[2]

  if(is.numeric(truth)==FALSE & is.logical(truth)==FALSE) truth<-as.numeric(truth)-1
   
  #CALCULATE EXACT AUC
  ord<-order(probs, decreasing=TRUE)
  probs <- probs[ord]; truth <- truth[ord]

  TPR=cumsum(truth)/max(1,sum(truth)) 
  FPR=cumsum(!truth)/max(1,sum(!truth))

  dup<-c(probs[-1]>=probs[-length(probs)], FALSE) 
  TPR<-c(0,TPR[!dup],1); FPR<-c(0,FPR[!dup],1)
  n <- length(TPR)
  auc<- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n]) )

  data.frame(acc,sens,spec,ppv,auc) 
}

# 10-fold cross validation
set.seed(1234)
k=10 #choose number of folds

data<-climate[sample(nrow(climate)),] #randomly order rows 
folds<-cut(seq(1:nrow(climate)),breaks=k,labels=F) #create folds

diags<-NULL 
for(i in 1:k){
  ## Create training and test sets
  train<-data[folds!=i,] 
  test<-data[folds==i,]
  truth<-test$temp_type ## Truth labels for fold i
  ## Train model on training set (all but fold i)
  fit4<-glm(temp_type~rainfall*period*city_name*temperature,data=train,family="binomial") 
  ## Test model on test set (fold i)
  probs<-predict(fit4,newdata = test,type="response")
  ## Get diagnostics for fold i
  diags<-rbind(diags,class_diag(probs,truth)) 
}

data.frame(acc=mean(diags$acc), sens=mean(diags$sens), spec=mean(diags$spec), ppv=mean(diags$ppv), auc=mean(diags$auc))
```
*The model has a precision of 81.86%. It correctly predicts maximum temperature type 83.04% of the time, and correctly predicts minimum temperature 81.59% of the time. Overall, the model has an accuracy of 82.31%. The AUC value is great, at 0.9185138. There are no signs of overfitting since the values are very similar to those from the model confusion matrix.* 
  
## LASSO Regression
```{r}
# LASSO regression
library(glmnet)
set.seed(1234)
y <- as.matrix(climate$temp_type) #grab response
x <- model.matrix(fit3)[, -1] #grab predictors
x <- scale(x)
cv.lasso1 <- cv.glmnet(x, y, family = "binomial")
lasso1 <- glmnet(x, y, family = "binomial", lambda = cv.lasso1$lambda.1se) 
coef(lasso1)

# 10-fold cross validation
# new binary variables for those with non-zero LASSO coef estimates
climate$city_Can <- ifelse(climate$city_name=="CANBERRA",1,0)
climate$city_Mel <- ifelse(climate$city_name=="MELBOURNE",1,0)
climate$city_Syd <- ifelse(climate$city_name=="SYDNEY",1,0)

set.seed(1234)
k=10 #choose number of folds

data<-climate[sample(nrow(climate)),] #randomly order rows 
folds<-cut(seq(1:nrow(climate)),breaks=k,labels=F) #create folds

diags<-NULL 
for(i in 1:k){
  ## Create training and test sets
  train<-data[folds!=i,] 
  test<-data[folds==i,]
  truth<-test$temp_type ## Truth labels for fold i
  ## Train model on training set (all but fold i)
  fit5<-glm(temp_type~rainfall*period*city_Mel*city_Can*city_Syd*temperature,data=train,family="binomial") 
  ## Test model on test set (fold i)
  probs<-predict(fit5,newdata = test,type="response")
  ## Get diagnostics for fold i
  diags<-rbind(diags,class_diag(probs,truth)) 
}

data.frame(acc=mean(diags$acc), sens=mean(diags$sens), spec=mean(diags$spec), ppv=mean(diags$ppv), auc=mean(diags$auc))
```
*The LASSO regression had non-zero coefficient estimates for rainfall, period, the cities of Melbourne, Canberra, and Sydney, and temperature. Perth had a slightly smaller p-value in the logistic regression but it was still significant. However, when present in an interaction with rainfall, period, and temperature, Perth had a non-zero coefficient estimate.*

*The accuracy of the LASSO regression was slightly smaller than the logistic regression (79.40%)*





